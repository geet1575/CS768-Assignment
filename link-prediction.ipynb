{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vedch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6545\n",
      "Number of edges: 32874\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the graph using pickle\n",
    "with open('new_build_parallel/citation_graph.gpickle', 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "\n",
    "# Display basic graph information\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_info(node_id):\n",
    "    \"\"\"Retrieve title and abstract information for a paper given its node ID.\n",
    "    \n",
    "    Args:\n",
    "        node_id: The ID of the paper node in the citation graph\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (title, abstract) where both can be None if not found\n",
    "    \"\"\"\n",
    "    # Load the mapping from citation graph id to folder\n",
    "    with open(\"new_build_parallel/citation_graph_id_to_folder.json\", \"r\") as f:\n",
    "        id_to_folder = json.load(f)\n",
    "    \n",
    "\n",
    "    # Get the folder path for the given node_id\n",
    "    folder_path = id_to_folder.get(f\"{node_id}\")\n",
    "\n",
    "    if not folder_path:\n",
    "        return None, None\n",
    "    \n",
    "    folder_path = os.path.join(\"../dataset_papers/dataset_papers\", folder_path) # set path as needed\n",
    "    # Extract title from title.txt\n",
    "    title = None\n",
    "    title_path = os.path.join(folder_path, \"title.txt\")\n",
    "    if os.path.exists(title_path):\n",
    "        with open(title_path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            title = f.read().strip()\n",
    "            \n",
    "    # Extract abstract from abstract.txt\n",
    "    abstract = None\n",
    "    abstract_path = os.path.join(folder_path, \"abstract.txt\")\n",
    "    if os.path.exists(abstract_path):\n",
    "        with open(abstract_path, \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            abstract = f.read().strip()\n",
    "            \n",
    "    return title, abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Statistics:\n",
      "Total samples: 52598\n",
      "Positive samples: 26299\n",
      "Negative samples: 26299\n",
      "\n",
      "Test Set Statistics:\n",
      "Total samples: 13150\n",
      "Positive samples: 6575\n",
      "Negative samples: 6575\n",
      "\n",
      "Training Set Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4862</td>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>4125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2349</td>\n",
       "      <td>6532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5547</td>\n",
       "      <td>1947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52593</th>\n",
       "      <td>2235</td>\n",
       "      <td>3092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52594</th>\n",
       "      <td>6403</td>\n",
       "      <td>4819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52595</th>\n",
       "      <td>3922</td>\n",
       "      <td>6388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52596</th>\n",
       "      <td>134</td>\n",
       "      <td>3347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52597</th>\n",
       "      <td>5657</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52598 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target  label\n",
       "0        4862     615      1\n",
       "1          87    1150      1\n",
       "2          91    4125      1\n",
       "3        2349    6532      1\n",
       "4        5547    1947      1\n",
       "...       ...     ...    ...\n",
       "52593    2235    3092      0\n",
       "52594    6403    4819      0\n",
       "52595    3922    6388      0\n",
       "52596     134    3347      0\n",
       "52597    5657     276      0\n",
       "\n",
       "[52598 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3152</td>\n",
       "      <td>4222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772</td>\n",
       "      <td>471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6538</td>\n",
       "      <td>2791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4119</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2060</td>\n",
       "      <td>1455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13145</th>\n",
       "      <td>5553</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13146</th>\n",
       "      <td>3442</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>1757</td>\n",
       "      <td>3733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13148</th>\n",
       "      <td>790</td>\n",
       "      <td>1729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>600</td>\n",
       "      <td>3820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  target  label\n",
       "0        3152    4222      1\n",
       "1         772     471      1\n",
       "2        6538    2791      1\n",
       "3        4119      10      1\n",
       "4        2060    1455      1\n",
       "...       ...     ...    ...\n",
       "13145    5553     219      0\n",
       "13146    3442     567      0\n",
       "13147    1757    3733      0\n",
       "13148     790    1729      0\n",
       "13149     600    3820      0\n",
       "\n",
       "[13150 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Extract all real edges (positive samples)\n",
    "edges = list(G.edges())\n",
    "\n",
    "# Step 2: Train-test split on positive edges\n",
    "train_edges, test_edges = train_test_split(edges, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Create training graph (with test edges removed)\n",
    "train_G = G.copy()\n",
    "train_G.remove_edges_from(test_edges)\n",
    "\n",
    "# Step 4: Sample negative edges (non-edges)\n",
    "\n",
    "nodes = list(train_G.nodes())\n",
    "\n",
    "# Use sets to avoid duplicate samples\n",
    "train_non_edges = set()\n",
    "while len(train_non_edges) < len(train_edges):\n",
    "    u, v = random.choice(nodes), random.choice(nodes)\n",
    "    if u != v and not train_G.has_edge(u, v):\n",
    "        train_non_edges.add((u, v))\n",
    "\n",
    "test_non_edges = set()\n",
    "while len(test_non_edges) < len(test_edges):\n",
    "    u, v = random.choice(nodes), random.choice(nodes)\n",
    "    if u != v and not G.has_edge(u, v):  # for test set, check on original full graph\n",
    "        test_non_edges.add((u, v))\n",
    "\n",
    "# Step 5: Prepare training and testing datasets\n",
    "X_train = train_edges + list(train_non_edges)\n",
    "y_train = [1] * len(train_edges) + [0] * len(train_non_edges)\n",
    "\n",
    "X_test = test_edges + list(test_non_edges)\n",
    "y_test = [1] * len(test_edges) + [0] * len(test_non_edges)\n",
    "\n",
    "# Step 6: Create DataFrames\n",
    "train_df = pd.DataFrame({\n",
    "    'source': [u for u, v in X_train],\n",
    "    'target': [v for u, v in X_train],\n",
    "    'label': y_train\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'source': [u for u, v in X_test],\n",
    "    'target': [v for u, v in X_test],\n",
    "    'label': y_test\n",
    "})\n",
    "\n",
    "# Step 7: Print dataset statistics\n",
    "print(\"\\nTraining Set Statistics:\")\n",
    "print(f\"Total samples: {len(train_df)}\")\n",
    "print(f\"Positive samples: {train_df['label'].sum()}\")\n",
    "print(f\"Negative samples: {len(train_df) - train_df['label'].sum()}\")\n",
    "\n",
    "print(\"\\nTest Set Statistics:\")\n",
    "print(f\"Total samples: {len(test_df)}\")\n",
    "print(f\"Positive samples: {test_df['label'].sum()}\")\n",
    "print(f\"Negative samples: {len(test_df) - test_df['label'].sum()}\")\n",
    "\n",
    "# Optionally preview the data\n",
    "print(\"\\nTraining Set Preview:\")\n",
    "display(train_df)\n",
    "print(\"\\nTest Set Preview:\")\n",
    "display(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful information for the nodes\n",
    "# Example: build id_to_title using your get_paper_info function\n",
    "id_to_title = {}\n",
    "id_to_abstract = {}\n",
    "for node in G.nodes():\n",
    "    title, abstract = get_paper_info(node)\n",
    "    id_to_title[node] = title if title else \"\"\n",
    "    id_to_abstract[node] = abstract if abstract else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute_title_overlap(df: pd.DataFrame, id_to_title: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a column to the DataFrame with the number of overlapping words in titles of source and target nodes.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'source' and 'target' columns\n",
    "    - id_to_title: Dictionary mapping node IDs to title strings\n",
    "    \n",
    "    Returns:\n",
    "    - df with a new column 'title_overlap'\n",
    "    \"\"\"\n",
    "    def overlap_count(row):\n",
    "        title_u = id_to_title.get(row['source'], \"\").lower().split()\n",
    "        title_v = id_to_title.get(row['target'], \"\").lower().split()\n",
    "        return len(set(title_u) & set(title_v))\n",
    "    \n",
    "    df['title_overlap'] = df.apply(overlap_count, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_abstract_overlap(df: pd.DataFrame, id_to_abstract: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a column to the DataFrame with the number of overlapping words in abstracts of source and target nodes.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'source' and 'target' columns\n",
    "    - id_to_abstract: Dictionary mapping node IDs to abstract strings\n",
    "    \n",
    "    Returns:\n",
    "    - df with a new column 'abstract_overlap'\n",
    "    \"\"\"\n",
    "    def overlap_count(row):\n",
    "        abstract_u = id_to_abstract.get(row['source'], \"\").lower().split()\n",
    "        abstract_v = id_to_abstract.get(row['target'], \"\").lower().split()\n",
    "        return len(set(abstract_u) & set(abstract_v))\n",
    "    \n",
    "    df['abstract_overlap'] = df.apply(overlap_count, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_title_cosine_similarity(df: pd.DataFrame, id_to_title: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a column with cosine similarity between TF-IDF vectors of titles.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'source' and 'target'\n",
    "    - id_to_title: Dictionary mapping node IDs to title strings\n",
    "    \n",
    "    Returns:\n",
    "    - df with a new column 'title_cosine'\n",
    "    \"\"\"\n",
    "    # Extract all unique titles needed\n",
    "    all_ids = pd.concat([df['source'], df['target']]).unique()\n",
    "    id_text_map = {i: id_to_title.get(i, \"\") for i in all_ids}\n",
    "\n",
    "    # Vectorize all titles\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    corpus = [id_text_map[i] for i in all_ids]\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Map node id to index in matrix\n",
    "    id_to_index = {i: idx for idx, i in enumerate(all_ids)}\n",
    "\n",
    "    # Compute cosine similarity for each pair\n",
    "    def sim(row):\n",
    "        i = id_to_index[row['source']]\n",
    "        j = id_to_index[row['target']]\n",
    "        return cosine_similarity(tfidf_matrix[i], tfidf_matrix[j])[0, 0]\n",
    "    \n",
    "    df['title_cosine'] = df.apply(sim, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_abstract_cosine_similarity(df: pd.DataFrame, id_to_abstract: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a column with cosine similarity between TF-IDF vectors of abstracts.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'source' and 'target'\n",
    "    - id_to_abstract: Dictionary mapping node IDs to abstract strings\n",
    "    \n",
    "    Returns:\n",
    "    - df with a new column 'abstract_cosine'\n",
    "    \"\"\"\n",
    "    all_ids = pd.concat([df['source'], df['target']]).unique()\n",
    "    id_text_map = {i: id_to_abstract.get(i, \"\") for i in all_ids}\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    corpus = [id_text_map[i] for i in all_ids]\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    id_to_index = {i: idx for idx, i in enumerate(all_ids)}\n",
    "\n",
    "    def sim(row):\n",
    "        i = id_to_index[row['source']]\n",
    "        j = id_to_index[row['target']]\n",
    "        return cosine_similarity(tfidf_matrix[i], tfidf_matrix[j])[0, 0]\n",
    "    \n",
    "    df['abstract_cosine'] = df.apply(sim, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(u, v, train_G):\n",
    "    if not train_G.has_node(u) or not train_G.has_node(v):\n",
    "        return 0  # or np.nan if you want to flag this\n",
    "    neighbors_u = set(train_G.neighbors(u))\n",
    "    neighbors_v = set(train_G.neighbors(v))\n",
    "    intersection = len(neighbors_u.intersection(neighbors_v))\n",
    "    union = len(neighbors_u.union(neighbors_v))\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "\n",
    "def compute_jaccard_similarity_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    df['jaccard_similarity'] = df.apply(lambda row: jaccard_similarity(row['source'], row['target'], train_G), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preferential_attachment(u, v, train_G):\n",
    "    \"\"\"\n",
    "    Computes the Preferential Attachment score between two nodes in the training graph.\n",
    "    \n",
    "    Parameters:\n",
    "    - u, v: Nodes for which to compute Preferential Attachment\n",
    "    - train_G: The training graph\n",
    "    \n",
    "    Returns:\n",
    "    - Preferential Attachment score between u and v\n",
    "    \"\"\"\n",
    "    if not train_G.has_node(u) or not train_G.has_node(v):\n",
    "        return 0  # or np.nan if you prefer\n",
    "    deg_u = train_G.degree(u)\n",
    "    deg_v = train_G.degree(v)\n",
    "    return deg_u * deg_v\n",
    "\n",
    "def compute_preferential_attachment_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    df['preferential_attachment'] = df.apply(lambda row: preferential_attachment(row['source'], row['target'], train_G), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def adamic_adar(u, v, train_G):\n",
    "    \"\"\"\n",
    "    Computes the Adamic-Adar Index between two nodes in the training graph.\n",
    "    \n",
    "    Parameters:\n",
    "    - u, v: Nodes for which to compute Adamic-Adar Index\n",
    "    - train_G: The training graph\n",
    "    \n",
    "    Returns:\n",
    "    - Adamic-Adar Index between u and v\n",
    "    \"\"\"\n",
    "    # Check if both nodes exist in the graph\n",
    "    if not train_G.has_node(u) or not train_G.has_node(v):\n",
    "        return 0  # or np.nan if you prefer\n",
    "\n",
    "    # Get the common neighbors between u and v\n",
    "    common_neighbors = set(train_G.neighbors(u)).intersection(train_G.neighbors(v))\n",
    "\n",
    "    # Calculate the Adamic-Adar index\n",
    "    return sum(1 / math.log(train_G.degree(w)) for w in common_neighbors if train_G.degree(w) > 1)\n",
    "\n",
    "def compute_adamic_adar_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    # Apply the Adamic-Adar index computation and check lengths\n",
    "    adamic_adar_values = df.apply(lambda row: adamic_adar(row['source'], row['target'], train_G), axis=1)\n",
    "    \n",
    "    # Check if the length of computed values matches the length of the DataFrame\n",
    "    print(f\"Length of computed values: {len(adamic_adar_values)}, Length of DataFrame: {len(df)}\")\n",
    "\n",
    "    # If lengths match, assign the computed values\n",
    "    if len(adamic_adar_values) == len(df):\n",
    "        df['adamic_adar'] = adamic_adar_values\n",
    "    else:\n",
    "        print(\"Mismatch in lengths! Check the applied function.\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbors(u, v, train_G):\n",
    "    \"\"\"\n",
    "    Computes the number of common neighbors between two nodes in the training graph.\n",
    "    \n",
    "    Parameters:\n",
    "    - u, v: Nodes for which to compute common neighbors\n",
    "    - train_G: The training graph\n",
    "    \n",
    "    Returns:\n",
    "    - Number of common neighbors between u and v\n",
    "    \"\"\"\n",
    "    # Check if both nodes exist in the graph\n",
    "    if not train_G.has_node(u) or not train_G.has_node(v):\n",
    "        return 0  # or np.nan if you prefer\n",
    "\n",
    "    # Get the neighbors for each node\n",
    "    neighbors_u = set(train_G.neighbors(u))\n",
    "    neighbors_v = set(train_G.neighbors(v))\n",
    "\n",
    "    # Return the number of common neighbors\n",
    "    return len(neighbors_u.intersection(neighbors_v))\n",
    "\n",
    "\n",
    "def compute_common_neighbors_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    df['common_neighbors'] = df.apply(lambda row: common_neighbors(row['source'], row['target'], train_G), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_resource_allocation(u, v, train_G):\n",
    "    \"\"\"\n",
    "    Computes the Community Resource Allocation (CRA) score between two nodes in the training graph.\n",
    "    \n",
    "    Parameters:\n",
    "    - u, v: Nodes for which to compute CRA\n",
    "    - train_G: The training graph\n",
    "    \n",
    "    Returns:\n",
    "    - CRA score between u and v\n",
    "    \"\"\"\n",
    "    # Ensure both nodes exist in the graph\n",
    "    if not train_G.has_node(u) or not train_G.has_node(v):\n",
    "        return 0  # or np.nan if you prefer\n",
    "    \n",
    "    # Get the common neighbors of u and v\n",
    "    common_neighbors = set(train_G.neighbors(u)).intersection(train_G.neighbors(v))\n",
    "\n",
    "    # If there are no common neighbors, return 0\n",
    "    if not common_neighbors:\n",
    "        return 0\n",
    "\n",
    "    # Calculate the CRA score\n",
    "    score = sum(1 / (train_G.degree(w) * (train_G.degree(u) + train_G.degree(v))) for w in common_neighbors)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_community_resource_allocation_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    df['community_resource_allocation'] = df.apply(lambda row: community_resource_allocation(row['source'], row['target'], train_G), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "def get_node_community_map(train_G):\n",
    "    communities = list(nx.algorithms.community.modularity_max.greedy_modularity_communities(train_G))\n",
    "    \n",
    "    node_to_community = {}\n",
    "    for idx, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            node_to_community[node] = idx\n",
    "    \n",
    "    return node_to_community\n",
    "\n",
    "def same_cluster_fast(u, v, node_to_community):\n",
    "    return int(node_to_community.get(u) == node_to_community.get(v))\n",
    "\n",
    "def compute_same_cluster_feature(df: pd.DataFrame, train_G) -> pd.DataFrame:\n",
    "    node_to_community = get_node_community_map(train_G)\n",
    "    df['same_cluster'] = df.apply(lambda row: same_cluster_fast(row['source'], row['target'], node_to_community), axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:33:07,810 - INFO - Computing title overlaps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing title overlap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:33:08,226 - INFO - Computing abstract overlaps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing abstract overlap\n",
      "Length of computed values: 52598, Length of DataFrame: 52598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:34:45,350 - INFO - Computing title overlaps...\n",
      "2025-05-04 21:34:45,456 - INFO - Computing abstract overlaps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing title overlap\n",
      "computing abstract overlap\n",
      "Length of computed values: 13150, Length of DataFrame: 13150\n",
      "   source  target  label  title_overlap  abstract_overlap  title_cosine  \\\n",
      "0    4862     615      1              0                20      0.000000   \n",
      "1      87    1150      1              2                24      0.205991   \n",
      "2      91    4125      1              0                18      0.000000   \n",
      "3    2349    6532      1              0                23      0.000000   \n",
      "4    5547    1947      1              0                25      0.000000   \n",
      "\n",
      "   abstract_cosine  jaccard_similarity  preferential_attachment  adamic_adar  \\\n",
      "0         0.105672            0.000000                      138     0.000000   \n",
      "1         0.196653            0.000000                      522     0.000000   \n",
      "2         0.051316            0.000000                      920     0.000000   \n",
      "3         0.059388            0.040268                     4060     1.388428   \n",
      "4         0.150296            0.000000                     2356     0.000000   \n",
      "\n",
      "   common_neighbors  community_resource_allocation  same_cluster  \n",
      "0                 0                       0.000000             1  \n",
      "1                 0                       0.000000             1  \n",
      "2                 0                       0.000000             1  \n",
      "3                 6                       0.000558             1  \n",
      "4                 0                       0.000000             1  \n",
      "   source  target  label  title_overlap  abstract_overlap  title_cosine  \\\n",
      "0    3152    4222      1              1                20      0.052680   \n",
      "1     772     471      1              1                23      0.243476   \n",
      "2    6538    2791      1              0                28      0.000000   \n",
      "3    4119      10      1              4                38      0.272967   \n",
      "4    2060    1455      1              0                19      0.000000   \n",
      "\n",
      "   abstract_cosine  jaccard_similarity  preferential_attachment  adamic_adar  \\\n",
      "0         0.113680            0.000000                       98     0.000000   \n",
      "1         0.224686            0.294118                      440     1.207526   \n",
      "2         0.078660            0.000000                      104     0.000000   \n",
      "3         0.258904            0.125000                       33     0.279055   \n",
      "4         0.052733            0.000000                     4800     0.000000   \n",
      "\n",
      "   common_neighbors  same_cluster  community_resource_allocation  \n",
      "0                 0             0                       0.000000  \n",
      "1                 5             1                       0.001776  \n",
      "2                 0             0                       0.000000  \n",
      "3                 1             0                       0.001984  \n",
      "4                 0             1                       0.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def extract_all_features(df, train_G, id_to_title, id_to_abstract):\n",
    "    \"\"\"\n",
    "    This function extracts all the features and appends them to the dataframe.\n",
    "\n",
    "    ```\n",
    "    Parameters:\n",
    "    - df: The input dataframe containing the source and target nodes for link prediction.\n",
    "    - train_G: The training graph for calculating graph-based features.\n",
    "\n",
    "    Returns:\n",
    "    - df: The dataframe with appended features.\n",
    "    \"\"\"\n",
    "    # Overlapping words in title\n",
    "    df = compute_title_overlap(df, id_to_title)\n",
    "\n",
    "    # Overlapping words in abstract\n",
    "    df = compute_abstract_overlap(df, id_to_abstract)\n",
    "\n",
    "    # Cosine similarity of titles\n",
    "    df = compute_title_cosine_similarity(df, id_to_title)\n",
    "\n",
    "    # Cosine similarity of abstracts\n",
    "    df = compute_abstract_cosine_similarity(df, id_to_abstract)\n",
    "\n",
    "    # Jaccard similarity coefficient\n",
    "    df = compute_jaccard_similarity_feature(df, train_G)\n",
    "\n",
    "    # Preferential attachment score\n",
    "    df = compute_preferential_attachment_feature(df, train_G)\n",
    "\n",
    "    # Adamic Adar Index\n",
    "    df = compute_adamic_adar_feature(df, train_G)\n",
    "\n",
    "    # Common neighbors\n",
    "    df = compute_common_neighbors_feature(df, train_G)\n",
    "\n",
    "    # Same Cluster (community)\n",
    "    df = compute_same_cluster_feature(df, train_G)\n",
    "\n",
    "    # Community resource allocation\n",
    "    df = compute_community_resource_allocation_feature(df, train_G)\n",
    "\n",
    "    return df\n",
    "\n",
    "# train_G is the graph used for feature extraction\n",
    "\n",
    "train_df = extract_all_features(train_df, train_G, id_to_title, id_to_abstract)\n",
    "test_df = extract_all_features(test_df, train_G, id_to_title, id_to_abstract)\n",
    "\n",
    "# Optionally display the first few rows of the updated DataFrames\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"ved_train_df.csv\", index=False)\n",
    "test_df.to_csv(\"ved_test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      6575\n",
      "           1       0.85      0.79      0.82      6575\n",
      "\n",
      "    accuracy                           0.82     13150\n",
      "   macro avg       0.82      0.82      0.82     13150\n",
      "weighted avg       0.82      0.82      0.82     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming train_df and test_df are already defined\n",
    "X_train = train_df.drop(columns=['label'])  # Features for training\n",
    "y_train = train_df['label']                # Target label for training\n",
    "\n",
    "X_test = test_df.drop(columns=['label'])  # Features for testing\n",
    "# Ensure X_test has the same columns as X_train\n",
    "X_test = X_test[X_train.columns]\n",
    "y_test = test_df['label']                # Target label for testing\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      6575\n",
      "           1       0.89      0.85      0.87      6575\n",
      "\n",
      "    accuracy                           0.87     13150\n",
      "   macro avg       0.88      0.87      0.87     13150\n",
      "weighted avg       0.88      0.87      0.87     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      6575\n",
      "           1       0.90      0.85      0.87      6575\n",
      "\n",
      "    accuracy                           0.88     13150\n",
      "   macro avg       0.88      0.88      0.88     13150\n",
      "weighted avg       0.88      0.88      0.88     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using XGBoost\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26299, number of negative: 26299\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2111\n",
      "[LightGBM] [Info] Number of data points in the train set: 52598, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      6575\n",
      "           1       0.90      0.85      0.88      6575\n",
      "\n",
      "    accuracy                           0.88     13150\n",
      "   macro avg       0.88      0.88      0.88     13150\n",
      "weighted avg       0.88      0.88      0.88     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using LightGBM\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      6575\n",
      "           1       0.90      0.86      0.88      6575\n",
      "\n",
      "    accuracy                           0.88     13150\n",
      "   macro avg       0.88      0.88      0.88     13150\n",
      "weighted avg       0.88      0.88      0.88     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81      6575\n",
      "           1       0.89      0.63      0.74      6575\n",
      "\n",
      "    accuracy                           0.78     13150\n",
      "   macro avg       0.81      0.78      0.77     13150\n",
      "weighted avg       0.81      0.78      0.77     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80      6575\n",
      "           1       0.83      0.72      0.77      6575\n",
      "\n",
      "    accuracy                           0.79     13150\n",
      "   macro avg       0.79      0.79      0.79     13150\n",
      "weighted avg       0.79      0.79      0.79     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78      6575\n",
      "           1       0.94      0.48      0.63      6575\n",
      "\n",
      "    accuracy                           0.72     13150\n",
      "   macro avg       0.80      0.72      0.71     13150\n",
      "weighted avg       0.80      0.72      0.71     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81      6575\n",
      "           1       0.78      0.91      0.84      6575\n",
      "\n",
      "    accuracy                           0.83     13150\n",
      "   macro avg       0.84      0.83      0.83     13150\n",
      "weighted avg       0.84      0.83      0.83     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      6575\n",
      "           1       0.90      0.83      0.87      6575\n",
      "\n",
      "    accuracy                           0.87     13150\n",
      "   macro avg       0.87      0.87      0.87     13150\n",
      "weighted avg       0.87      0.87      0.87     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      6575\n",
      "           1       0.85      0.79      0.82      6575\n",
      "\n",
      "    accuracy                           0.82     13150\n",
      "   macro avg       0.82      0.82      0.82     13150\n",
      "weighted avg       0.82      0.82      0.82     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79      6575\n",
      "           1       0.84      0.66      0.74      6575\n",
      "\n",
      "    accuracy                           0.77     13150\n",
      "   macro avg       0.78      0.77      0.76     13150\n",
      "weighted avg       0.78      0.77      0.76     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.96      0.79      6575\n",
      "           1       0.92      0.53      0.67      6575\n",
      "\n",
      "    accuracy                           0.74     13150\n",
      "   macro avg       0.80      0.74      0.73     13150\n",
      "weighted avg       0.80      0.74      0.73     13150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
